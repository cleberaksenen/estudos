{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "686c82d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn import linear_model\n",
    "from sklearn import tree\n",
    "from sklearn import naive_bayes\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "45697dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dados = pd.read_excel(\"./data/dados_cerveja_nota.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf7e8c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Definição da classe\n",
    "dados[\"aprovado\"] = dados[\"nota\"] >= 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "152c1112",
   "metadata": {},
   "source": [
    "### Regressão logistica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "44d00858",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz:\n",
      "        False  True\n",
      "False      5     1\n",
      "True       1     8\n",
      "Acurácia: 0.8666666666666667\n",
      "Precisão: 0.8888888888888888\n",
      "Precisão: 0.8888888888888888\n"
     ]
    }
   ],
   "source": [
    "RL = linear_model.LogisticRegression(penalty=None, fit_intercept=True)\n",
    "\n",
    "### Ajuste do modelo (aprendizagem)\n",
    "RL.fit(dados[[\"cerveja\"]], dados[\"aprovado\"])\n",
    "\n",
    "### Predição em cima da mesma base\n",
    "RL_predict = RL.predict(dados[[\"cerveja\"]])\n",
    "\n",
    "### Matriz de confusão\n",
    "RL_matriz = metrics.confusion_matrix(dados[\"aprovado\"], RL_predict)\n",
    "RL_matriz = pd.DataFrame(RL_matriz, \n",
    "                         index = [\"False\", \"True\"],\n",
    "                         columns=[\"False\", \"True\"])\n",
    "\n",
    "print(\"Matriz:\\n\", RL_matriz)\n",
    "\n",
    "### Métricas\n",
    "RL_acuracia = metrics.accuracy_score(dados[\"aprovado\"], RL_predict)\n",
    "print(\"Acurácia:\", RL_acuracia)\n",
    "\n",
    "RL_precisao = metrics.precision_score(dados[\"aprovado\"], RL_predict)\n",
    "print(\"Precisão:\", RL_precisao)\n",
    "\n",
    "RL_recall = metrics.recall_score(dados[\"aprovado\"], RL_predict)\n",
    "print(\"Precisão:\", RL_recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ded100c",
   "metadata": {},
   "source": [
    "### Árvore de decisão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6b03747c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz:\n",
      "        False  True\n",
      "False      6     0\n",
      "True       1     8\n",
      "Acurácia: 0.9333333333333333\n",
      "Precisão: 1.0\n",
      "Precisão: 0.8888888888888888\n"
     ]
    }
   ],
   "source": [
    "arvore = tree.DecisionTreeClassifier(max_depth=2)\n",
    "\n",
    "### Ajuste do modelo (aprendizagem)\n",
    "arvore.fit(dados[[\"cerveja\"]], dados[\"aprovado\"])\n",
    "\n",
    "### Predição em cima da mesma base\n",
    "arvore_predict = arvore.predict(dados[[\"cerveja\"]])\n",
    "\n",
    "### Matriz de confusão\n",
    "arvore_matriz = metrics.confusion_matrix(dados[\"aprovado\"], arvore_predict)\n",
    "arvore_matriz = pd.DataFrame(arvore_matriz, \n",
    "                         index = [\"False\", \"True\"],\n",
    "                         columns=[\"False\", \"True\"])\n",
    "\n",
    "print(\"Matriz:\\n\", arvore_matriz)\n",
    "\n",
    "### Métricas\n",
    "arvore_acuracia = metrics.accuracy_score(dados[\"aprovado\"], arvore_predict)\n",
    "print(\"Acurácia:\", arvore_acuracia)\n",
    "\n",
    "arvore_precisao = metrics.precision_score(dados[\"aprovado\"], arvore_predict)\n",
    "print(\"Precisão:\", arvore_precisao)\n",
    "\n",
    "arvore_recall = metrics.recall_score(dados[\"aprovado\"], arvore_predict)\n",
    "print(\"Precisão:\", arvore_recall)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a08c2039",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "194b6849",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz:\n",
      "        False  True\n",
      "False      5     1\n",
      "True       1     8\n",
      "Acurácia: 0.8666666666666667\n",
      "Precisão: 0.8888888888888888\n",
      "Precisão: 0.8888888888888888\n"
     ]
    }
   ],
   "source": [
    "NB = naive_bayes.GaussianNB()\n",
    "\n",
    "### Ajuste do modelo (aprendizagem)\n",
    "NB.fit(dados[[\"cerveja\"]], dados[\"aprovado\"])\n",
    "\n",
    "### Predição em cima da mesma base\n",
    "NB_predict = NB.predict(dados[[\"cerveja\"]])\n",
    "\n",
    "### Matriz de confusão\n",
    "NB_matriz = metrics.confusion_matrix(dados[\"aprovado\"], NB_predict)\n",
    "NB_matriz = pd.DataFrame(NB_matriz, \n",
    "                         index = [\"False\", \"True\"],\n",
    "                         columns=[\"False\", \"True\"])\n",
    "\n",
    "print(\"Matriz:\\n\", NB_matriz)\n",
    "\n",
    "### Métricas\n",
    "NB_acuracia = metrics.accuracy_score(dados[\"aprovado\"], NB_predict)\n",
    "print(\"Acurácia:\", NB_acuracia)\n",
    "\n",
    "NB_precisao = metrics.precision_score(dados[\"aprovado\"], NB_predict)\n",
    "print(\"Precisão:\", NB_precisao)\n",
    "\n",
    "NB_recall = metrics.recall_score(dados[\"aprovado\"], NB_predict)\n",
    "print(\"Precisão:\", NB_recall)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
